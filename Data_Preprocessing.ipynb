{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarhatem97/ANER_DEV/blob/main/Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Wr5jtRRn80"
      },
      "source": [
        "Dataset Preprocessing\n",
        "=====================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This dataset is coming from wikepedia articles.\n",
        "\n",
        "Dataset has 50 Difeerent classes, summarized down below \n",
        "\n",
        "Source: https://fsalotaibi.kau.edu.sa/Pages-Arabic-NE-Corpora.aspx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbUl9VhF83Dh",
        "outputId": "ffc8cedb-c893-40fb-cfd9-0bda1077c759"
      },
      "source": [
        "\n",
        "# Here we download the dataset\n",
        "\n",
        "! gdown --id 1uq33al1VNubM7eA5CEMlQstpBohRNPky\n",
        "!gdown --id 1w_AwpWAdi_IPWYlV0VzFE6WL7doWopiL\n",
        "\n",
        "\n",
        "!gdown --id 14E2KGO5qNWDPlWtwRJR0gqhhzlUhB9z6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Aqmar \n",
        "!gdown --id 1SlmQpysO72B-fy23asTIWsb0kEq2zx2r"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1uq33al1VNubM7eA5CEMlQstpBohRNPky\n",
            "To: /content/WikiFANE_Gold_2014_500K.csv\n",
            "7.18MB [00:00, 43.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w_AwpWAdi_IPWYlV0VzFE6WL7doWopiL\n",
            "To: /content/WikiFANE_Gold_2014_500K.txt\n",
            "7.69MB [00:00, 35.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14E2KGO5qNWDPlWtwRJR0gqhhzlUhB9z6\n",
            "To: /content/NewsFANE_Gold_2014_170K.txt\n",
            "2.65MB [00:00, 84.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SlmQpysO72B-fy23asTIWsb0kEq2zx2r\n",
            "To: /content/Football.txt\n",
            "100% 30.6k/30.6k [00:00<00:00, 52.7MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBw39VlR9UWS"
      },
      "source": [
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I49kLaXie4zi"
      },
      "source": [
        "Here we clean the dataset, by removing newlines and some unicode characters,\n",
        "\n",
        "And finally we insert newline token between sentences "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJ6Lzl_9ZW6"
      },
      "source": [
        "\n",
        "\n",
        "# dataset = 'WikiFANE_Gold_2014_500K.tx'\n",
        "# out_name = 'dataset_1.0.txt '\n",
        "\n",
        "# dataset = 'NewsFANE_Gold_2014_170K.txt'\n",
        "# out_name = 'ANER_dataset.txt'\n",
        "\n",
        "dataset = 'Football.txt'\n",
        "out_name = 'aqmar_test.txt'\n",
        "\n",
        "\n",
        "\n",
        "lines =[]\n",
        "with open(dataset,'r', encoding='utf-8')as f:\n",
        "  with open(out_name,'w',encoding='utf-8') as out:\n",
        "    for line in f:\n",
        "\n",
        "      line = line.replace(u'\\u200e','')\n",
        "      line = line.replace(u'\\ufeff','')\n",
        "      line = line.strip('\\n')\n",
        "\n",
        "      parts = line.split('\\t')\n",
        "      # parts = line.split(' ')\n",
        "\n",
        "      # if this an empty line, add newline token\n",
        "      if len(parts[0]) == 0:\n",
        "        parts[0] = '[NEWLINE]'\n",
        "        out.write(f'{parts[0]}\\n')\n",
        "\n",
        "      else: \n",
        "         out.write(f'{parts[0]} {parts[1]}\\n')\n",
        "\n",
        "      lines.append(parts)\n",
        "     \n",
        "     \n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7-XyNKCgflJ"
      },
      "source": [
        "Here we save the dataset as a csv file, and then read it to do some analysis on it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpa6S3b5T0Lm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32e07c4-8389-4396-daaf-b3f30ad7983d"
      },
      "source": [
        "\n",
        "df = pd.DataFrame(lines)\n",
        "\n",
        "df.to_csv('ANER_dataset.csv',index=False, header=None, encoding='utf-8',mode = 'w')\n",
        "\n",
        "csv_data = pd.read_csv('ANER_dataset.csv',encoding='utf-8', header=None,quoting=csv.QUOTE_NONE, error_bad_lines=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 40: expected 2 fields, saw 3\\nSkipping line 258: expected 2 fields, saw 3\\nSkipping line 1097: expected 2 fields, saw 3\\n'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7JfybbhhDN7"
      },
      "source": [
        "We can see here that we have over 500k tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN93rIPuMHZo",
        "outputId": "a0723f0f-8c03-424d-d4a1-3d579a13e289"
      },
      "source": [
        "\n",
        "\n",
        "print(csv_data.shape)\n",
        "print(csv_data.head(10))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2754, 2)\n",
            "        0        1\n",
            "0     كرة  B-MISS1\n",
            "1   القدم   I-MIS1\n",
            "2   رياضة        O\n",
            "3  جماعية        O\n",
            "4       ،        O\n",
            "5     يضم        O\n",
            "6    فريق        O\n",
            "7     كرة   B-MIS1\n",
            "8   القدم   I-MIS1\n",
            "9      11        O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MKSo91ChNBQ"
      },
      "source": [
        "This is a list with all the classes we have "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RueEa71Z998O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de396968-0c44-41cc-dce8-fc35552440d6"
      },
      "source": [
        "classes = csv_data.apply(set)\n",
        "classes[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC',\n",
              " 'B-MIS0',\n",
              " 'B-MIS1',\n",
              " 'B-MIS2',\n",
              " 'B-MISS1',\n",
              " 'B-ORG',\n",
              " 'B-PER',\n",
              " 'I-LOC',\n",
              " 'I-MIS0',\n",
              " 'I-MIS1',\n",
              " 'I-MIS2',\n",
              " 'I-ORG',\n",
              " 'I-PER',\n",
              " 'O',\n",
              " 'OO',\n",
              " nan}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKGmxJqThoVa"
      },
      "source": [
        "Here we get the frequenct of each class seperatley, to get insight about the weight of each class "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbVxc9DX-_43",
        "outputId": "c36736fa-c34d-4ee3-8ef5-ab985ea07b51"
      },
      "source": [
        "class_freq = dict()\n",
        "\n",
        "\n",
        "for  row in tqdm(csv_data[1]):\n",
        "  cls = str(row)\n",
        "  if cls in class_freq.keys():\n",
        "    class_freq[cls] += 1\n",
        "  else:\n",
        "    class_freq[cls] = 1\n",
        "\n",
        "\n",
        "class_freq = sorted(class_freq.items(), key=lambda x:x[1], reverse=True)\n",
        "\n",
        "\n",
        "for cls, freq in class_freq:\n",
        "  print(f' {cls}: {freq}')\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2754/2754 [00:00<00:00, 587394.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " O: 2451\n",
            " nan: 96\n",
            " I-ORG: 47\n",
            " B-ORG: 30\n",
            " B-MIS1: 24\n",
            " B-LOC: 24\n",
            " I-MIS1: 20\n",
            " I-MIS0: 17\n",
            " B-MIS0: 11\n",
            " B-MIS2: 11\n",
            " I-LOC: 8\n",
            " B-PER: 5\n",
            " I-MIS2: 4\n",
            " I-PER: 4\n",
            " B-MISS1: 1\n",
            " OO: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q23aY4ryiG43"
      },
      "source": [
        "Here we just make sure that the sum of all class tokens equals the total number of tokens in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OttbPmvA-M5A",
        "outputId": "4203710b-9391-4768-9470-dafae20d354c"
      },
      "source": [
        "df = pd.DataFrame(class_freq)\n",
        "\n",
        "\n",
        "print(df.sum(axis=1).sum())\n",
        "print(len(csv_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172839\n",
            "172839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFxncM4iiaMv"
      },
      "source": [
        "Here we just save the classes frequencies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_-SCiLd-ODM",
        "outputId": "19c66544-78fd-458a-afdb-5263cd5ee62a"
      },
      "source": [
        "with open('classes.txt','w') as f:\n",
        "  for i in tqdm(class_freq):\n",
        "    f.write(f'{i[0]}: {i[1]} \\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 58203.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4m_bUiHTZXP"
      },
      "source": [
        "Classes Summary\n",
        "-------------\n",
        "\n",
        "We have 50 difeerent classes with 5 different categories "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mix60aiLUpoy"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "Weapone\n",
        "--------\n",
        "\n",
        "- Blunt\n",
        "- Exploding\n",
        "- Nuclear\n",
        "- Projectile\n",
        "- Sharp\n",
        "- Shooting\n",
        "\n",
        "Miscellaneous\n",
        "--------------\n",
        "- Chemical (only 7 tokens)\n",
        "- Drug (100 tokens )\n",
        "- Food (around 150 token)\n",
        "- Hardware\n",
        "- Movie\n",
        "- Software\n",
        "- Sound\n",
        "- Celestial\n",
        "- Book\n",
        "- Air (airplanes)\n",
        "\n",
        "\n",
        "PERSON\n",
        "--------------\n",
        "- Artist\n",
        "- Politician \n",
        "- Businessperson\n",
        "- Engineer\n",
        "- Group\n",
        "- Athlete\n",
        "- Lawyer\n",
        "- Other_PER\n",
        "- Police\n",
        "- Scientist\n",
        "- Religious_PER\n",
        "\n",
        "\n",
        "LOCATION\n",
        "--------------\n",
        "- Continent\n",
        "- County-or-District\n",
        "- GPE-Cluster\n",
        "- Land\n",
        "- Land-Region-Natural\n",
        "- Nation\n",
        "- Path\n",
        "- Population-Center\n",
        "- State-or-Province\n",
        "- Subarea-Facility\n",
        "- Water\n",
        "- Water-Body\n",
        "- Building-Grounds\n",
        "- Airport\n",
        "\n",
        "\n",
        "ORGANIZATION\n",
        "--------------\n",
        "- Commercial (company names)\n",
        "- Educational (shcools, colleges, etc)\n",
        "- Entertainment\n",
        "- Government\n",
        "- Non-Governmental\n",
        "- Media\n",
        "- Medical-Science\n",
        "- Plant\n",
        "- Religious_ORG\n",
        "- Sports\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UvLjW7-igdA"
      },
      "source": [
        "Finally we save the dataset to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qCQ1fuTHkCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2a6ef5-236c-4bf9-92be-cc3a3be7389f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmOn7cZp6_DD"
      },
      "source": [
        "!cp ANER_dataset.csv ANER_dataset.txt drive/MyDrive/Datasets/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km_Fb9277Kds"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}